---
title: '3. Summarize Telemetry in GitHub Actions'
layout: default
nav_order: 3
parent: 'Exercise 06: AI Governance and Model Observability'
---

# Task 03 - Summarize Telemetry in GitHub Actions

## Description

In this task you will extend your CI/CD pipeline by adding a step to your GitHub Actions workflow that automatically queries your workspace-based telemetry and publishes a summary in the job output.
You’ll use the Azure CLI `log-analytics` extension to run a Kusto query against your Kusto Query Language (KQL) log table (`AppEvents`), summarizing event count, average latency and p95 latency grouped by model version — all without leaving GitHub.
This enables every deployment to surface AI observability metrics directly in the workflow summary for immediate visibility and tracking performance snapshots over time.

## Success Criteria

- The GitHub Actions workflow contains a step named “Summarize ChatCompletion telemetry (last 24h)” which runs *always* (`if: always()`), regardless of deployment outcome.
- The workflow securely installs or upgrades the `log-analytics` CLI extension in a non-interactive way (`az extension add --name log-analytics --upgrade --yes --allow-preview || true`).
- The step uses the an environment variable (ex. `LOG_WORKSPACE_ID`) to reference the Log Analytics workspace ID and runs a KQL query similar to:

    ```kusto
    AppEvents
    | where TimeGenerated > ago(24h)
    | where Name == 'ChatCompletion'
    | extend ModelVersion = tostring(parse_json(Properties).ModelVersion)
    | extend durationMs = todouble(parse_json(Measurements).CompletionLatencyMs)
    | summarize totalEvents = count(), avgDurationMs = avg(durationMs), p95DurationMs = percentile(durationMs,95)
        by bin(TimeGenerated,10m), ModelVersion
    | project TimeGenerated, ModelVersion, totalEvents, avgDurationMs, p95DurationMs
    | order by TimeGenerated asc
    ```

- The results of the query are appended to the `$GITHUB_STEP_SUMMARY` and display a table of model versions, event counts, average latency, and p95 latency.
- If the environment variable `LOG_WORKSPACE_ID` is missing or telemetry query fails, the step emits a clear diagnostic message and exits gracefully without failing the overall workflow.

## Learning Resources

- [Azure Monitor Logs: Get started with log queries](https://learn.microsoft.com/en-us/azure/azure-monitor/logs/get-started-queries)
- [Azure CLI: az monitor log-analytics query](https://learn.microsoft.com/en-us/cli/azure/monitor/log-analytics?view=azure-cli-latest)
- [GitHub Actions: Workflow commands for GitHub Actions](https://docs.github.com/en/actions/using-workflows/workflow-commands-for-github-actions)
- [GitHub Actions: Store information in variables](https://docs.github.com/en/actions/how-tos/write-workflows/choose-what-workflows-do/use-variables)

## Key Tasks

### 01: Add a step after deployment

Try this prompt to get started with Copilot:

```text
/agent add a step to my GitHub Actions workflow that queries Log Analytics for
AppEvents telemetry using the Azure CLI and appends the results to the GitHub
step summary. Use RBAC authentication and avoid API keys. Include a minimal read me
explaining any required GitHub configuration changes or Azure permission updates.
```

![Add a step to my GitHub Actions workflow](../../media/06_03-workflow-prompt.png)

<details markdown="block">
<summary>Workflow step</summary>

```yaml
  - name: Summarize ChatCompletion telemetry (last 24h)
    if: always()
    shell: bash {0}
    run: |
      echo "### ChatCompletion Telemetry (last 24h)" >> $GITHUB_STEP_SUMMARY
      echo "Workspace: ${{ env.LOG_WORKSPACE_ID }}" >> $GITHUB_STEP_SUMMARY
      if [ -z "${{ env.LOG_WORKSPACE_ID }}" ]; then
        echo "_LOG_WORKSPACE_ID not set — skipping telemetry summary._" >> $GITHUB_STEP_SUMMARY
        exit 0
      fi

      # Ensure required extension
      az extension add --name log-analytics --upgrade --yes --allow-preview >/dev/null 2>&1 || true

      # Define KQL query using a proper here-doc
      read -r -d '' QUERY <<'EOF'
      AppEvents
      | where TimeGenerated > ago(24h)
      | where Name == 'ChatCompletion'
      | extend props = parse_json(Properties), meas = parse_json(Measurements)
      | extend ModelVersion = tostring(props.ModelVersion)
      | extend durationMs = todouble(meas.InferenceLatencyMs)
      | summarize totalEvents = count(), avgDurationMs = avg(durationMs), p95DurationMs = percentile(durationMs,95)
          by ModelVersion
      | order by ModelVersion asc
      EOF

      # Run query and format Markdown output
      RESULTS=$(az monitor log-analytics query \
        --workspace ${{ env.LOG_WORKSPACE_ID }} \
        --analytics-query "$QUERY" \
        --output tsv 2>/dev/null || echo "")

      if [ -z "$RESULTS" ]; then
        echo "_No ChatCompletion telemetry found in the last 24 hours._" >> $GITHUB_STEP_SUMMARY
        exit 0
      fi

      echo "" >> $GITHUB_STEP_SUMMARY
      echo "| ModelVersion | Events | Avg (ms) | P95 (ms) |" >> $GITHUB_STEP_SUMMARY
      echo "|--------------|---------|-----------|-----------|" >> $GITHUB_STEP_SUMMARY
      echo "$RESULTS" | awk '{printf "| %s | %s | %s | %s |\n", $1, $2, int($3), int($4)}' >> $GITHUB_STEP_SUMMARY
```

</details>

<details markdown="block">

After Copilot adds the telemetry step and you have reviewed it, check the configuration doc it created for next steps.  Follow the steps to configure GitHub and Azure.

<summary>Generated Configuration Steps</summary>

# ChatCompletion Telemetry Summary Step

A lightweight Azure Monitor Logs query has been added to the GitHub Actions workflow `.github/workflows/deploy.yml` to surface recent Chat / ChatCompletion related request performance after each deployment.

## What It Does
After the App Service restart, the step runs:

```bash
az monitor logs query --workspace <LOG_WORKSPACE_ID> --analytics-query "<KQL>" --output table
```

Its output (or any error message) is appended to the GitHub Actions Job Summary so you can quickly inspect request volume and latency trends for the last 24 hours without leaving GitHub.

## New Repository Variables
| Name | Type | Required | Purpose |
|------|------|----------|---------|
| `AZURE_LOG_WORKSPACE_ID` | Repository Variable | Required | The Log Analytics Workspace ID that holds your Application Insights / Azure Monitor telemetry. |

Set this under: Repo Settings → Variables → New variable.

> You can obtain the Workspace ID via: Azure Portal → Log Analytics Workspace → Overview → Workspace ID.

## Service Principal Permissions
The existing secret `AZURE_CREDENTIALS` is reused (no new secret needed). Ensure the service principal used there has read access to the Log Analytics workspace. Grant ONE of the following (least privilege first):

1. Role assignment at Workspace scope: `Log Analytics Reader`
2. OR at Subscription / Resource Group scope: `Monitoring Reader`

No write / contributor rights are required for this query.

## Customizing the Query
Edit the `QUERY` string inside the workflow step `Summarize ChatCompletion telemetry (last 24h)`. Current KQL (using `AppEvents` in Log Analytics):

```kusto
AppEvents
| where TimeGenerated > ago(24h)
| where Name == "ChatCompletion"
| extend props = parse_json(Properties)
| extend meas = parse_json(Measurements)
| extend ModelVersion = tostring(props["ModelVersion"])
| extend durationMs = todouble(meas["CompletionLatencyMs"])
| summarize totalEvents = count(),
          avgDurationMs = avg(durationMs),
          p95DurationMs = percentile(durationMs,95)
          by bin(TimeGenerated,10m), ModelVersion
| project TimeGenerated, ModelVersion, totalEvents, avgDurationMs, p95DurationMs
| order by TimeGenerated asc
```

Adjust filters (e.g., `Name == "ChatCompletion"`) to match your event naming. If you store latency under a different measurement key, change `CompletionLatencyMs`.

## Troubleshooting
| Symptom | Likely Cause | Fix |
|---------|--------------|-----|
| Summary shows message about missing `LOG_WORKSPACE_ID` | Variable not set | Create repository variable `AZURE_LOG_WORKSPACE_ID` with your Workspace ID |
| Query failed / unauthorized | Missing Reader role | Assign `Log Analytics Reader` or `Monitoring Reader` role to the SP |
| Empty table | No matching telemetry last 24h | Widen time window or adjust filters |

## Quick Verification
From your local shell (with Azure CLI logged in and permission):
```bash
az monitor logs query --workspace $AZURE_LOG_WORKSPACE_ID --analytics-query "AppEvents | where Name == 'ChatCompletion' | take 1" --output table
```

---
Minimal by design. Extend only if a clearer need arises.

</details>

### 02: Verify Data Ingestion

Before committing your new workflow and running it for the first time, validate the generated Kusto query by running it directly in the Log Analytics query.  Copy the query from the generated configuration document (if provided) or directly from the workflow step.  For example:

```kusto
AppEvents
| where Name == "ChatCompletion"
| extend props = parse_json(Properties)
| extend meas = parse_json(Measurements)
| extend ModelVersion = tostring(props["ModelVersion"])
| extend durationMs = todouble(meas["CompletionLatencyMs"])
| summarize avgLatency = avg(durationMs) by ModelVersion
```

Results confirm telemetry flow.  If there are any errors, work with Copilot to resolve them.

### 03: Test Your Workflow

#### 1. **Commit and push the updated workflow file**
   Save your changes in `.github/workflows/deploy.yml`, commit them to your local branch, and push to GitHub.

   ```bash
   git add .github/workflows/deploy.yml
   git commit -m "Add telemetry summary step to deployment workflow"
   git push
````

#### 2. **Watch the workflow run**

   * In your GitHub repository, go to **Actions** → select the latest workflow run.
   * Confirm that the workflow starts automatically when you push to the main branch or if you are still working with an open PR it should trigger as well (run it manually using **Run workflow** if needed).
   * Observe the **Summarize ChatCompletion telemetry (last 24h)** step in the job log, it should execute even if earlier steps fail, because it uses `if: always()`.

#### 3. **Locate the summary output**

   * When the workflow completes, open the **Summary** tab for the run.
   * Scroll to the section titled **ChatCompletion Telemetry (last 24h)**.
   * You should see a formatted table showing columns for `TimeGenerated`, `ModelVersion`, `totalEvents`, `avgDurationMs`, and `p95DurationMs`.
   * If telemetry is still propagating, you may see a message such as:
     `Telemetry query failed (verify workspace id, data ingestion, and SP permissions).`

![Workflow summary](../../media/06_03-workflow-stats.png)

#### 4. **Validate results**

   * Confirm that data matches what you see in your Log Analytics workspace.
   * Check that the summary updates with each new run, providing a quick performance snapshot for each deployment.

**You have now integrated live telemetry into your GitHub Actions workflow**, allowing you to monitor AI model performance directly within your CI/CD pipeline.

## Summary

You've completed this task. You have extended your CI/CD pipeline by adding a step to your GitHub Actions workflow that automatically queries your workspace-based telemetry and publishes a summary in the job output.
